{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example IMC analysis with Morpheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 (optional): set seed for reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import seed_everything\n",
    "seed_everything(42)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating a SpatialDataset Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will start by creating a `SpatialDataset` object, which will hold all relevant information about the dataset we will be working with. \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To create a `SpatialDataset` object, you will need:\n",
    "- The path to the CSV file containing all single-cell expression information\n",
    "- A list of channel names\n",
    "\n",
    "### CSV File Structure\n",
    "\n",
    "The expected structure of the CSV file is as follows:\n",
    "- Each row corresponds to a single cell\n",
    "- Columns for each channel name, with expression values specified\n",
    "- Five additional columns with the following names and information:\n",
    "\n",
    "| Column Name         | Description                               |\n",
    "|---------------------|-------------------------------------------|\n",
    "| `ImageNumber`       | Unique ID for each image                  |\n",
    "| `PatientID`         | Unique ID for each patient                |\n",
    "| `CellType`          | Cell type                                 |\n",
    "| `Location_Center_X` | X coordinate of the cell center in micron |\n",
    "| `Location_Center_Y` | Y coordinate of the cell center in micron |\n",
    "\n",
    "Note: Additional columns beyond these will not be used for the analysis performed in this tutorial.\n",
    "\n",
    "To create a `SpatialDataset` object, use the following code, remember to replace `'path/to/your/csv/file.csv'` with the actual path to your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morpheus as mp\n",
    "\n",
    "data_path = \"/groups/mthomson/zwang2/IMC/output/cedarsLiver_sz48_pxl3_nc44/temp/singlecell.csv\"  # change to your own directory\n",
    "dataset = mp.SpatialDataset(input_path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: patch images and mask cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16  # Patch size in pixels\n",
    "pixel_size = 3  # Pixel size in microns\n",
    "cell_types = [\"Tcytotoxic\", \"Tumor\"]  # Specify the cell types of interest\n",
    "mask_cell_types = [\"Tcytotoxic\"]\n",
    "dataset.generate_masked_patch(\n",
    "    cell_to_mask=mask_cell_types,\n",
    "    cell_types=cell_types,\n",
    "    patch_size=patch_size,\n",
    "    pixel_size=pixel_size,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "# example metadata\n",
    "print(dataset.metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: generate data splits for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to generate train, validation, and test data splits for model training. We want to stratify our splits by the label we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = \"Contains_Tcytotoxic\"\n",
    "dataset.generate_data_splits(stratify_by=colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: train classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize model\n",
    "# model_arch = \"unet\"\n",
    "# n_channels = dataset.n_channels\n",
    "# img_size = dataset.img_size\n",
    "# model = mp.PatchClassifier(n_channels, img_size, model_arch)\n",
    "\n",
    "# # train model\n",
    "# trainer_params = {\n",
    "#     \"max_epochs\": 100,  # set to >60 for better performance\n",
    "#     \"accelerator\": \"auto\",\n",
    "#     \"logger\": False,\n",
    "# }\n",
    "# model = mp.train(\n",
    "#     model=model,\n",
    "#     dataset=dataset,\n",
    "#     label_name=colname,\n",
    "#     trainer_params=trainer_params,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: generate counterfactuals using trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images to generate counterfactuals\n",
    "dataset.get_split_info()\n",
    "select_metadata = dataset.metadata[\n",
    "    (dataset.metadata[\"Contains_Tumor\"] == 1)\n",
    "    & (dataset.metadata[\"Contains_Tcytotoxic\"] == 0)\n",
    "    & (dataset.metadata[\"splits\"] == \"train\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels allowed to be perturbed\n",
    "channel_to_perturb = [\n",
    "    \"Glnsynthetase\",\n",
    "    \"CCR4\",\n",
    "    \"PDL1\",\n",
    "    \"LAG3\",\n",
    "    \"CD105endoglin\",\n",
    "    \"TIM3\",\n",
    "    \"CXCR4\",\n",
    "    \"PD1\",\n",
    "    \"CYR61\",\n",
    "    \"CD44\",\n",
    "    \"IL10\",\n",
    "    \"CXCL12\",\n",
    "    \"CXCR3\",\n",
    "    \"Galectin9\",\n",
    "    \"YAP\",\n",
    "]\n",
    "\n",
    "# probability cutoff for classification\n",
    "threshold = 0.43\n",
    "\n",
    "# optimization parameters\n",
    "optimization_param = {\n",
    "    \"use_kdtree\": True,\n",
    "    \"theta\": 40.0,\n",
    "    \"kappa\": (threshold - 0.5) * 2,\n",
    "    \"learning_rate_init\": 0.1,\n",
    "    \"beta\": 1.0,\n",
    "    \"max_iterations\": 1000,  # set to >1000 for better performance\n",
    "    \"c_init\": 1000.0,\n",
    "    \"c_steps\": 5,\n",
    "}\n",
    "\n",
    "# load model\n",
    "model = mp.load_model(f\"{dataset.root_dir}/model/checkpoints/epoch=41-step=12432.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Generate counterfactuals using trained model\n",
    "cf = mp.get_counterfactual(\n",
    "    images=select_metadata,\n",
    "    dataset=dataset,\n",
    "    target_class=1,\n",
    "    model=model,\n",
    "    channel_to_perturb=channel_to_perturb,\n",
    "    optimization_params=optimization_param,\n",
    "    threshold=threshold,\n",
    "    save_dir=f\"{dataset.root_dir}/cf/\",\n",
    "    device=\"cpu\",\n",
    "    num_workers=os.cpu_count() - 1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
