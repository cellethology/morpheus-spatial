{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example IMC analysis with Morpheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 (optional): set seed for reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import seed_everything\n",
    "seed_everything(42)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating a SpatialDataset Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will start by creating a `SpatialDataset` object, which will hold all relevant information about the dataset we will be working with. \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To create a `SpatialDataset` object, you will need:\n",
    "- The path to the CSV file containing all single-cell expression information\n",
    "- A list of channel names\n",
    "\n",
    "### CSV File Structure\n",
    "\n",
    "The expected structure of the CSV file is as follows:\n",
    "- Each row corresponds to a single cell\n",
    "- Columns for each channel name, with expression values specified\n",
    "- Five additional columns with the following names and information:\n",
    "\n",
    "| Column Name         | Description                               |\n",
    "|---------------------|-------------------------------------------|\n",
    "| `ImageNumber`       | Unique ID for each image                  |\n",
    "| `PatientID`         | Unique ID for each patient                |\n",
    "| `CellType`          | Cell type                                 |\n",
    "| `Location_Center_X` | X coordinate of the cell center in micron |\n",
    "| `Location_Center_Y` | Y coordinate of the cell center in micron |\n",
    "\n",
    "Note: Additional columns beyond these will not be used for the analysis performed in this tutorial.\n",
    "\n",
    "To create a `SpatialDataset` object, use the following code, remember to replace `'path/to/your/csv/file.csv'` with the actual path to your CSV file, and `['channel1', 'channel2', ...]` with the list of your channel names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 17:56:26.865092: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 17:56:47.346661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /central/home/zwang2/anaconda3/lib/python3.8/site-packages/nvidia/cudnn/:/central/slurm/install/current/lib/:\n",
      "2024-04-05 17:56:47.347368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /central/home/zwang2/anaconda3/lib/python3.8/site-packages/nvidia/cudnn/:/central/slurm/install/current/lib/:\n",
      "2024-04-05 17:56:47.347383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import morpheus as mp\n",
    "\n",
    "data_path = \"/groups/mthomson/zwang2/IMC/output/cedarsLiver_sz48_pxl3_nc44/temp/singlecell.csv\"  # change to your own directory\n",
    "dataset = mp.SpatialDataset(\n",
    "    input_path=data_path,\n",
    "    channel_names=[\n",
    "        \"CD45\",\n",
    "        \"Glnsynthetase\",\n",
    "        \"CD163\",\n",
    "        \"NKG2D\",\n",
    "        \"CCR4\",\n",
    "        \"PDL1\",\n",
    "        \"FAP\",\n",
    "        \"CD11c\",\n",
    "        \"LAG3\",\n",
    "        \"HepPar1\",\n",
    "        \"FOXP3\",\n",
    "        \"aSMA\",\n",
    "        \"CD4\",\n",
    "        \"CD105endoglin\",\n",
    "        \"CD68\",\n",
    "        \"VISTA\",\n",
    "        \"CD20\",\n",
    "        \"CD8a\",\n",
    "        \"TIM3\",\n",
    "        \"CXCR4\",\n",
    "        \"PD1\",\n",
    "        \"iNOS\",\n",
    "        \"CD31\",\n",
    "        \"CYR61\",\n",
    "        \"CDX2\",\n",
    "        \"CAIX\",\n",
    "        \"CD3\",\n",
    "        \"CD44\",\n",
    "        \"CD15\",\n",
    "        \"CD11b\",\n",
    "        \"HLADR\",\n",
    "        \"IL10\",\n",
    "        \"CXCL12\",\n",
    "        \"HLAABC\",\n",
    "        \"DNA1\",\n",
    "        \"DNA2\",\n",
    "        \"GranzymeB\",\n",
    "        \"Ki67\",\n",
    "        \"HistoneH3\",\n",
    "        \"CXCR3\",\n",
    "        \"Galectin9\",\n",
    "        \"YAP\",\n",
    "        \"CD14\",\n",
    "        \"CK19\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: patch images and mask cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16  # Patch size in pixels\n",
    "pixel_size = 3  # Pixel size in microns\n",
    "cell_types = [\"Tcytotoxic\", \"Tumor\"]  # Specify the cell types of interest\n",
    "mask_cell_types = [\"Tcytotoxic\"]\n",
    "dataset.generate_masked_patch(\n",
    "    cell_to_mask=mask_cell_types,\n",
    "    cell_types=cell_types,\n",
    "    patch_size=patch_size,\n",
    "    pixel_size=pixel_size,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "# example metadata\n",
    "print(dataset.metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: generate data splits for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to generate train, validation, and test data splits for model training. We want to stratify our splits by the label we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = \"Contains_Tcytotoxic\"\n",
    "dataset.generate_data_splits(stratify_by=colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: train classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_arch = \"unet\"\n",
    "n_channels = dataset.n_channels\n",
    "img_size = dataset.img_size\n",
    "model = mp.PatchClassifier(n_channels, img_size, model_arch)\n",
    "\n",
    "# train model\n",
    "trainer_params = {\n",
    "    \"max_epochs\": 100,  # set to >60 for better performance\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"logger\": False,\n",
    "}\n",
    "model = mp.train(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    label_name=colname,\n",
    "    trainer_params=trainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: generate counterfactuals using trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model if needed\n",
    "model = mp.load_model(dataset.model_dir + \"/checkpoints/epoch=41-step=12432.ckpt\")\n",
    "\n",
    "# images to generate counterfactuals\n",
    "dataset.get_split_info()\n",
    "select_metadata = dataset.metadata[\n",
    "    (dataset.metadata[\"Contains_Tumor\"] == 1)\n",
    "    & (dataset.metadata[\"Contains_Tcytotoxic\"] == 0)\n",
    "    & (dataset.metadata[\"splits\"] == \"train\")\n",
    "    & (dataset.metadata[\"ImageNumber\"] == 202)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels allowed to be perturbed\n",
    "channel_to_perturb = [\n",
    "    \"Glnsynthetase\",\n",
    "    \"CCR4\",\n",
    "    \"PDL1\",\n",
    "    \"LAG3\",\n",
    "    \"CD105endoglin\",\n",
    "    \"TIM3\",\n",
    "    \"CXCR4\",\n",
    "    \"PD1\",\n",
    "    \"CYR61\",\n",
    "    \"CD44\",\n",
    "    \"IL10\",\n",
    "    \"CXCL12\",\n",
    "    \"CXCR3\",\n",
    "    \"Galectin9\",\n",
    "    \"YAP\",\n",
    "]\n",
    "\n",
    "# probability cutoff for classification\n",
    "threshold = 0.43\n",
    "\n",
    "# optimization parameters\n",
    "optimization_param = {\n",
    "    \"use_kdtree\": True,\n",
    "    \"theta\": 40.0,\n",
    "    \"kappa\": -0.14,  # set to: (threshold - 0.5) * 2\n",
    "    \"learning_rate_init\": 0.1,\n",
    "    \"beta\": 80.0,\n",
    "    \"max_iterations\": 1000,  # set to >1000 for better performance\n",
    "    \"c_init\": 1000.0,\n",
    "    \"c_steps\": 5,\n",
    "}\n",
    "\n",
    "# Generate counterfactuals using trained model\n",
    "cf = mp.get_counterfactual(\n",
    "    images=select_metadata.sample(frac=1),\n",
    "    dataset=dataset,\n",
    "    target_class=1,\n",
    "    model=model,\n",
    "    channel_to_perturb=channel_to_perturb,\n",
    "    optimization_params=optimization_param,\n",
    "    threshold=threshold,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morpheus-spatial-ndDQRg-x-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
