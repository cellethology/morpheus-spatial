{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpheus tutorial with example data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate the complete Morpheus pipeline using an example data set from [Wang et al. (2023)]('https://doi.org/10.1016/j.cmet.2023.04.013'). This data set contains 209 tumor images taken from 30 patients with colorectal cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Download data set and set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install morpheus if not already installed\n",
    "!pip install morpheus-spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import morpheus as mp\n",
    "\n",
    "from lightning.pytorch import seed_everything\n",
    "seed_everything(42) # Optional: sets seed for pytorch, numpy, python.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the input data from an online data repository, which consists of an input csv file and a txt file containing the channel names. For reproduction purpose, a trained model and patient split will also be downloaded and loaded into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(record_id, filename, save_path):\n",
    "    # check if save_path exists:\n",
    "    if not os.path.exists(save_path):\n",
    "        url = f\"https://data.caltech.edu/records/{record_id}/files/{filename}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(save_path)\n",
    "        print(f\"Downloaded {filename} to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Data already exists in {save_path}\")\n",
    "\n",
    "\n",
    "# Download input data from the Caltech Data Portal\n",
    "download_and_unzip(\"465sy-9g558\", \"crc_tutorial.zip\", save_path=\"crc_tutorial\")\n",
    "\n",
    "# For paper reproduction purpose: load patient split and trained model\n",
    "model_path = \"crc_tutorial/model/unet.ckpt\"\n",
    "with open(\"crc_tutorial/patient_split.json\", \"r\") as file:\n",
    "    patient_split = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating a SpatialDataset Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a `SpatialDataset` object, which will hold all relevant information about the dataset we will be working with. \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To create a `SpatialDataset` object, you will need:\n",
    "- The path to the input CSV file containing all single-cell expression information\n",
    "- A list of channel names\n",
    "\n",
    "### CSV File Structure\n",
    "\n",
    "The expected structure of the CSV file is as follows:\n",
    "- Each row corresponds to a single cell\n",
    "- Columns for each channel name, with expression values specified\n",
    "- Five additional columns with the following names and information:\n",
    "\n",
    "| Column Name         | Description                               | Datatype    |\n",
    "|---------------------|-------------------------------------------|-------------|\n",
    "| `ImageNumber`       | Unique ID for each image                  | Integer     |\n",
    "| `PatientID`         | Unique ID for each patient                | Str/Integer |\n",
    "| `CellType`          | Cell type                                 | Str         |\n",
    "| `Location_Center_X` | X coordinate of the cell center in micron | Float       |\n",
    "| `Location_Center_Y` | Y coordinate of the cell center in micron | Float       |\n",
    "\n",
    "Note: Additional metadata columns beyond these will not be used in this tutorial.\n",
    "\n",
    "To create a `SpatialDataset` object, specify the path to a single cell csv file and the corresponding list of channel names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mp.SpatialDataset(\n",
    "    input_path=\"crc_tutorial/singlecell.csv\",\n",
    "    channel_path=\"crc_tutorial/channel_names.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: patch images and mask cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will generate image patches (of specified size and resolution) using the spatial data set, followed by masking out cytotoxic T cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16  # Patch size in pixels\n",
    "pixel_size = 3  # Pixel size in microns\n",
    "cell_types = [\"Tcytotoxic\", \"Tumor\"]  # Specify the cell types of interest\n",
    "mask_cell_types = [\"Tcytotoxic\"]\n",
    "dataset.generate_masked_patch(\n",
    "    cell_to_mask=mask_cell_types,\n",
    "    cell_types=cell_types,\n",
    "    patch_size=patch_size,\n",
    "    pixel_size=pixel_size,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: generate data splits for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate train, validation, and test data splits for model training, where split is done at the patient level. We want to stratify our splits by the label we want to predict by specifying the `stratify_by` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = \"Contains_Tcytotoxic\"\n",
    "dataset.generate_data_splits(\n",
    "    stratify_by=colname,\n",
    "    specify_split=patient_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: train classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating data splits, we train a unet model to predict the presence of T cells from masked patches. A model instance is first created using the `PatchClassifier` class and trained by calling the `train` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_arch = \"unet\"\n",
    "n_channels = dataset.n_channels\n",
    "img_size = dataset.img_size\n",
    "\n",
    "model = mp.PatchClassifier(n_channels, img_size, model_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer_params = {\n",
    "    \"max_epochs\": 30,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"logger\": False,\n",
    "}\n",
    "model = mp.train(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    predict_label=colname,\n",
    "    trainer_params=trainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: generate counterfactuals using trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we subset for training patches containing tumor but no T cells. These patches will be used to generate counterfactuals. Note that we will build a kdtree from the training patches when we first execute `get_counterfactual`, this process will be done only once. \n",
    "\n",
    "Counterfactual generation per instance may be on the order of minutes. For large number of input instances, setting `num_workers` to be greater than 1 enables Ray parallelization and speeds things up. However, for tens of thousands of instances or more, counterfactual generation will still be slow without distributing the instances across a large cluster. Follow instructions [here]('https://doi.org/10.1016/j.cmet.2023.04.013') for using Ray with Slurm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tumor patches that do not contain T cells from training cohort to generate counterfactuals\n",
    "select_metadata = dataset.metadata[\n",
    "    (dataset.metadata[\"Contains_Tumor\"] == 1)\n",
    "    & (dataset.metadata[\"Contains_Tcytotoxic\"] == 0)\n",
    "    & (dataset.metadata[\"splits\"] == \"train\")\n",
    "]\n",
    "\n",
    "# example of selected instances to generate counterfactuals\n",
    "print(f\"Number of selected instances: {len(select_metadata)}\")\n",
    "print(select_metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for counterfactual generation\n",
    "optimization_param = {\n",
    "    \"use_kdtree\": True,\n",
    "    \"theta\": 50.0,\n",
    "    \"kappa\": -0.34,\n",
    "    \"learning_rate_init\": 0.1,\n",
    "    \"beta\": 80.0,\n",
    "    \"max_iterations\": 1000,\n",
    "    \"c_init\": 1000.0,\n",
    "    \"c_steps\": 5,\n",
    "    \"channel_to_perturb\": [\n",
    "        \"Glnsynthetase\",\n",
    "        \"CCR4\",\n",
    "        \"PDL1\",\n",
    "        \"LAG3\",\n",
    "        \"CD105endoglin\",\n",
    "        \"TIM3\",\n",
    "        \"CXCR4\",\n",
    "        \"PD1\",\n",
    "        \"CYR61\",\n",
    "        \"CD44\",\n",
    "        \"IL10\",\n",
    "        \"CXCL12\",\n",
    "        \"CXCR3\",\n",
    "        \"Galectin9\",\n",
    "        \"YAP\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Generate counterfactuals using trained model\n",
    "mp.get_counterfactual(\n",
    "    images=select_metadata,\n",
    "    dataset=dataset,\n",
    "    target_class=1,\n",
    "    model_path=model_path,\n",
    "    optimization_params=optimization_param,\n",
    "    save_dir=f\"{dataset.root_dir}/cf/example/\",\n",
    "    device=\"cpu\",\n",
    "    num_workers=1, # set to greater than 1 for cpu parallelization with Ray\n",
    "    verbosity=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morpheus-dev",
   "language": "python",
   "name": "morpheus-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
