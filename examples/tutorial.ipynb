{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neonine2/morpheus-spatial/blob/master/examples/tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpheus tutorial with example data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate the complete Morpheus pipeline using an example data set from [Wang et al. (2023)]('https://doi.org/10.1016/j.cmet.2023.04.013'). This data set contains 209 tumor images taken from 30 patients with colorectal cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running this notebook in Google Colab, please select 'Runtime' -> 'Change runtime type' ->  set 'Runtime type' to Python 3 and Hardward accelerator to 'GPU'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Download data set and set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: morpheus-spatial in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (1.0.4)\n",
      "Requirement already satisfied: requests in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (2.32.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.4 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from morpheus-spatial) (3.1.4)\n",
      "Requirement already satisfied: aiohttp>=3.9.4 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (3.10.4)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from morpheus-spatial) (2024.7.4)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.8 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from morpheus-spatial) (0.3.8)\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.10.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (3.11.0)\n",
      "Requirement already satisfied: idna>=3.7 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from morpheus-spatial) (3.7)\n",
      "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from morpheus-spatial) (2.3.3)\n",
      "Requirement already satisfied: numpy<=1.26 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (1.26.0)\n",
      "Requirement already satisfied: pandas==2.2.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (2.2.1)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (10.4.0)\n",
      "Requirement already satisfied: ray<3.0.0,>=2.11.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (2.34.0)\n",
      "Requirement already satisfied: scikit-learn>=1.5.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (1.5.1)\n",
      "Requirement already satisfied: torch==2.0.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (2.0.0)\n",
      "Requirement already satisfied: torchvision<0.16.0,>=0.15.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from morpheus-spatial) (0.15.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from pandas==2.2.1->morpheus-spatial) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from pandas==2.2.1->morpheus-spatial) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from pandas==2.2.1->morpheus-spatial) (2024.1)\n",
      "Requirement already satisfied: filelock in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (4.12.2)\n",
      "Requirement already satisfied: sympy in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (1.13.2)\n",
      "Requirement already satisfied: networkx in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from torch==2.0.0->morpheus-spatial) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->morpheus-spatial) (72.2.0)\n",
      "Requirement already satisfied: wheel in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->morpheus-spatial) (0.44.0)\n",
      "Requirement already satisfied: cmake in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from triton==2.0.0->torch==2.0.0->morpheus-spatial) (3.30.2)\n",
      "Requirement already satisfied: lit in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.0->morpheus-spatial) (18.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from aiohttp>=3.9.4->morpheus-spatial) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from Jinja2>=3.1.4->morpheus-spatial) (2.1.5)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from lightning<3.0.0,>=2.0.0->morpheus-spatial) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->morpheus-spatial) (2024.6.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from lightning<3.0.0,>=2.0.0->morpheus-spatial) (0.11.6)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from lightning<3.0.0,>=2.0.0->morpheus-spatial) (24.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from lightning<3.0.0,>=2.0.0->morpheus-spatial) (1.4.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from lightning<3.0.0,>=2.0.0->morpheus-spatial) (4.66.5)\n",
      "Requirement already satisfied: pytorch-lightning in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from lightning<3.0.0,>=2.0.0->morpheus-spatial) (2.3.3)\n",
      "Requirement already satisfied: click>=7.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from ray<3.0.0,>=2.11.0->morpheus-spatial) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from ray<3.0.0,>=2.11.0->morpheus-spatial) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from ray<3.0.0,>=2.11.0->morpheus-spatial) (1.0.8)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from ray<3.0.0,>=2.11.0->morpheus-spatial) (5.27.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from scikit-learn>=1.5.0->morpheus-spatial) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from scikit-learn>=1.5.0->morpheus-spatial) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from scikit-learn>=1.5.0->morpheus-spatial) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1->morpheus-spatial) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from jsonschema->ray<3.0.0,>=2.11.0->morpheus-spatial) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from jsonschema->ray<3.0.0,>=2.11.0->morpheus-spatial) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib64/python3.9/site-packages (from jsonschema->ray<3.0.0,>=2.11.0->morpheus-spatial) (0.20.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages (from sympy->torch==2.0.0->morpheus-spatial) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install morpheus if not already installed\n",
    "!pip install morpheus-spatial requests\n",
    "\n",
    "#reload notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-15 19:30:34,985\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import morpheus as mp\n",
    "\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(42)  # Optional: sets seed for pytorch, numpy, python.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the input data from an online data repository, which consists of an input csv file and a txt file containing the channel names. \n",
    "\n",
    "For reproduction purpose, a trained model and patient split will also be downloaded and used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists in crc_tutorial\n"
     ]
    }
   ],
   "source": [
    "def download_and_unzip(record_id, filename, save_path):\n",
    "    # check if save_path exists:\n",
    "    if not os.path.exists(save_path):\n",
    "        url = f\"https://data.caltech.edu/records/{record_id}/files/{filename}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(save_path)\n",
    "        print(f\"Downloaded {filename} to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Data already exists in {save_path}\")\n",
    "\n",
    "\n",
    "# Download input data from the Caltech Data Portal\n",
    "download_and_unzip(\"pr14s-wgk05\", \"crc_tutorial.zip\", save_path=\"crc_tutorial\")\n",
    "\n",
    "# For paper reproduction purpose: load patient split and trained model\n",
    "model_path = \"crc_tutorial/model/unet.ckpt\"\n",
    "with open(\"crc_tutorial/patient_split.json\", \"r\") as file:\n",
    "    patient_split = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating a SpatialDataset Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a `SpatialDataset` object, which will hold all relevant information about the dataset we will be working with. \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To create a `SpatialDataset` object, you will need:\n",
    "- The path to the input CSV file containing all single-cell expression information\n",
    "- A list of channel names\n",
    "\n",
    "### CSV File Structure\n",
    "\n",
    "The expected structure of the CSV file is as follows:\n",
    "- Each row corresponds to a single cell\n",
    "- Columns for each channel name, with expression values specified\n",
    "- Five additional columns with the following names and information:\n",
    "\n",
    "| Column Name         | Description                               | Datatype    |\n",
    "|---------------------|-------------------------------------------|-------------|\n",
    "| `ImageNumber`       | Unique ID for each image                  | Integer     |\n",
    "| `PatientID`         | Unique ID for each patient                | Str/Integer |\n",
    "| `CellType`          | Cell type<sup>†</sup>                     | Str         |\n",
    "| `Location_Center_X` | X coordinate of the cell center in micron | Float       |\n",
    "| `Location_Center_Y` | Y coordinate of the cell center in micron | Float       |\n",
    "\n",
    "**<sup>†</sup>Important**: in the `CellType` column, cytotoxic T cells must be labeled as `Tcytotoxic` and tumor cells must be labeled as `Tumor`. Additional cell types and metadata columns beyond those listed here will not be used in this tutorial.\n",
    "\n",
    "To create a `SpatialDataset` object, specify the path to a single cell csv file and the corresponding list of channel names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mp.SpatialDataset(\n",
    "    input_path=\"crc_tutorial/singlecell.csv\",\n",
    "    channel_path=\"crc_tutorial/channel_names.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: patch images and mask cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will generate image patches (of specified size and resolution) using the spatial data set, followed by masking out cytotoxic T cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File crc_tutorial/patch.h5 already exists, existing file loaded\n",
      "Total number of patches: 61008\n"
     ]
    }
   ],
   "source": [
    "patch_size = 16  # Patch size in pixels\n",
    "pixel_size = 3  # Pixel size in microns\n",
    "cell_types = [\"Tcytotoxic\", \"Tumor\"]  # Specify the cell types of interest\n",
    "mask_cell_types = [\"Tcytotoxic\"]\n",
    "dataset.generate_masked_patch(\n",
    "    cell_to_mask=mask_cell_types,\n",
    "    cell_types=cell_types,\n",
    "    patch_size=patch_size,\n",
    "    pixel_size=pixel_size,\n",
    "    save=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: generate data splits for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate train, validation, and test data splits for model training, where split is done at the patient level. We want to stratify our splits by the label we want to predict by specifying the `stratify_by` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits already exist in crc_tutorial/split\n"
     ]
    }
   ],
   "source": [
    "colname = \"Contains_Tcytotoxic\"\n",
    "dataset.generate_data_splits(\n",
    "    stratify_by=colname,\n",
    "    specify_split=patient_split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: train classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating data splits, we train a unet model to predict the presence of T cells from masked patches. A model instance is first created using the `PatchClassifier` class and trained by calling the `train` function. \n",
    "\n",
    "Feel free to skip this step and proceed directly to step 5 as a trained model has already been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_arch = \"unet\"\n",
    "n_channels = dataset.n_channels\n",
    "img_size = dataset.img_size\n",
    "\n",
    "model = mp.PatchClassifier(n_channels, img_size, model_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /central/home/zwang2/.cache/pypoetry/virtualenvs/mor ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/central/home/zwang2/.cache/pypoetry/virtualenvs/morpheus-spatial-ndDQRg-x-py3.9/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /central/home/zwang2/morpheus-spatial/morpheus/examples/crc_tutorial/model exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with unet architecture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | predictor | Sequential | 14.7 M | train\n",
      "-------------------------------------------------\n",
      "14.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.7 M    Total params\n",
      "58.760    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 319/319 [00:24<00:00, 13.12it/s, val_bce=0.569, val_precision=0.726, val_recall=0.161, val_bmc=0.297, val_auroc=0.753, val_f1=0.258, val_acc=0.868]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 319/319 [00:24<00:00, 12.97it/s, val_bce=0.569, val_precision=0.726, val_recall=0.161, val_bmc=0.297, val_auroc=0.753, val_f1=0.258, val_acc=0.868]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /central/home/zwang2/morpheus-spatial/morpheus/examples/crc_tutorial/model/epoch=0-step=319-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to /central/home/zwang2/morpheus-spatial/morpheus/examples/crc_tutorial/model/epoch=0-step=319-v5.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at /central/home/zwang2/morpheus-spatial/morpheus/examples/crc_tutorial/model/epoch=0-step=319-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 107/107 [00:03<00:00, 31.11it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8512948155403137\n",
      "       test_auroc           0.7843853831291199\n",
      "        test_bce            0.5781962275505066\n",
      "        test_bmc            0.38460588455200195\n",
      "         test_f1            0.40968289971351624\n",
      "     test_precision         0.6974540948867798\n",
      "       test_recall          0.29762837290763855\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "trainer_params = {\n",
    "    \"max_epochs\": 1,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"logger\": False,\n",
    "}\n",
    "model = mp.train(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    predict_label=colname,\n",
    "    trainer_params=trainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: generate counterfactuals using trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in perturbations that can drive T cells to infiltrate tumor, we only need to generate counterfactuals (cf) for (training) patches containing tumor but no T cells. We pass theses specific patches to `get_counterfactual` under the parameter `images` along with the path to a trained classifier under the parameter `model_path`. Note that by default a pre-downloaded unet is passed as argument for reproduction purposes, you can change this to point to your own trained unet from the train step above.\n",
    "\n",
    "During cf generation, we will build a kdtree from the training patches. Then this kdtree is used to generate countefactual for each patch independently. Hence cf generation can (and needs to) be parallelized to achieve massive speed boos. Counterfactual generation per instance may be on the order of minutes. For large number of input instances, setting `num_workers` to be greater than 1 enables Ray parallelization and speeds things up. In order to complete cf generation on the order of hours (instead of days), we will need to distribute the instances across a large cluster, follow instructions [here]('https://doi.org/10.1016/j.cmet.2023.04.013') for using Ray with Slurm. A HPC version of this tutorial notebook that includes slurm job submission will be available soon, feel free to open a github issue if this would be helpful to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected instances: 11831\n",
      "    patch_id  ImageNumber  PatientID  PatchIndex_X  PatchIndex_Y  \\\n",
      "0          0            2          2             0             0   \n",
      "2          2            2          2             0             2   \n",
      "12        12            2          2             0            12   \n",
      "13        13            2          2             0            13   \n",
      "14        14            2          2             0            14   \n",
      "\n",
      "    Contains_Tcytotoxic  Contains_Tumor splits  \n",
      "0                 False            True  train  \n",
      "2                 False            True  train  \n",
      "12                False            True  train  \n",
      "13                False            True  train  \n",
      "14                False            True  train  \n"
     ]
    }
   ],
   "source": [
    "# select tumor patches that do not contain T cells from training cohort to generate counterfactuals\n",
    "dataset.get_split_info()\n",
    "select_metadata = dataset.metadata[\n",
    "    (dataset.metadata[\"Contains_Tumor\"] == 1)\n",
    "    & (dataset.metadata[\"Contains_Tcytotoxic\"] == 0)\n",
    "    & (dataset.metadata[\"splits\"] == \"train\")\n",
    "]\n",
    "\n",
    "# example of selected instances to generate counterfactuals\n",
    "print(f\"Number of selected instances: {len(select_metadata)}\")\n",
    "print(select_metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for counterfactual generation\n",
    "optimization_param = {\n",
    "    \"use_kdtree\": True,\n",
    "    \"theta\": 50.0,\n",
    "    \"kappa\": -0.34,\n",
    "    \"learning_rate_init\": 0.1,\n",
    "    \"beta\": 80.0,\n",
    "    \"max_iterations\": 1000,\n",
    "    \"c_init\": 1000.0,\n",
    "    \"c_steps\": 5,\n",
    "    \"channel_to_perturb\": [\n",
    "        \"Glnsynthetase\",\n",
    "        \"CCR4\",\n",
    "        \"PDL1\",\n",
    "        \"LAG3\",\n",
    "        \"CD105endoglin\",\n",
    "        \"TIM3\",\n",
    "        \"CXCR4\",\n",
    "        \"PD1\",\n",
    "        \"CYR61\",\n",
    "        \"CD44\",\n",
    "        \"IL10\",\n",
    "        \"CXCL12\",\n",
    "        \"CXCR3\",\n",
    "        \"Galectin9\",\n",
    "        \"YAP\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Generate counterfactuals using trained model\n",
    "mp.get_counterfactual(\n",
    "    images=select_metadata,\n",
    "    dataset=dataset,\n",
    "    target_class=1,\n",
    "    model_path=model_path, # for paper reproduction purpose, set to pre-downloaded model\n",
    "    optimization_params=optimization_param,\n",
    "    save_dir=f\"{dataset.root_dir}/cf/example/\",\n",
    "    device=\"cpu\",\n",
    "    num_workers=1,  # set to greater than 1 for cpu parallelization with Ray\n",
    "    verbosity=0,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morpheus-spatial-ndDQRg-x-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
