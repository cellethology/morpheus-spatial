{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neonine2/morpheus-spatial/blob/master/examples/tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpheus tutorial with example data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate the complete Morpheus pipeline using an example data set from [Wang et al. (2023)]('https://doi.org/10.1016/j.cmet.2023.04.013'). This data set contains 209 tumor images taken from 30 patients with colorectal cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running this notebook in Google Colab, please select 'Runtime' -> 'Change runtime type' ->  set 'Runtime type' to Python 3 and Hardward accelerator to 'GPU'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Download data set and set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install morpheus if not already installed\n",
    "!pip install morpheus-spatial requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import json\n",
    "import os\n",
    "import morpheus as mp\n",
    "\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "seed_everything(42)  # Optional: sets seed for pytorch, numpy, python.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the input data from an online data repository, which consists of an input csv file and a txt file containing the channel names. \n",
    "\n",
    "For reproduction purpose, a trained model and patient split will also be downloaded and used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(record_id, filename, save_path):\n",
    "    # check if save_path exists:\n",
    "    if not os.path.exists(save_path):\n",
    "        url = f\"https://data.caltech.edu/records/{record_id}/files/{filename}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(save_path)\n",
    "        print(f\"Downloaded {filename} to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Data already exists in {save_path}\")\n",
    "\n",
    "\n",
    "# Download input data from the Caltech Data Portal\n",
    "download_and_unzip(\"pr14s-wgk05\", \"crc_tutorial.zip\", save_path=\"crc_tutorial\")\n",
    "\n",
    "# For paper reproduction purpose: load patient split and trained model\n",
    "model_path = \"crc_tutorial/model/unet.ckpt\"\n",
    "with open(\"crc_tutorial/patient_split.json\", \"r\") as file:\n",
    "    patient_split = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Creating a SpatialDataset Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating a `SpatialDataset` object, which will hold all relevant information about the dataset we will be working with. \n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "To create a `SpatialDataset` object, you will need:\n",
    "- The path to the input CSV file containing all single-cell expression information\n",
    "- A list of channel names\n",
    "\n",
    "### CSV File Structure\n",
    "\n",
    "The expected structure of the CSV file is as follows:\n",
    "- Each row corresponds to a single cell\n",
    "- Columns for each channel name, with expression values specified\n",
    "- Five additional columns with the following names and information:\n",
    "\n",
    "| Column Name         | Description                               | Datatype    |\n",
    "|---------------------|-------------------------------------------|-------------|\n",
    "| `ImageNumber`       | Unique ID for each image                  | Integer     |\n",
    "| `PatientID`         | Unique ID for each patient                | Str/Integer |\n",
    "| `CellType`          | Cell type<sup>†</sup>                     | Str         |\n",
    "| `Location_Center_X` | X coordinate of the cell center in micron | Float       |\n",
    "| `Location_Center_Y` | Y coordinate of the cell center in micron | Float       |\n",
    "\n",
    "**<sup>†</sup>Important**: in the `CellType` column, cytotoxic T cells must be labeled as `Tcytotoxic` and tumor cells must be labeled as `Tumor`. Additional cell types and metadata columns beyond those listed here will not be used in this tutorial.\n",
    "\n",
    "To create a `SpatialDataset` object, specify the path to a single cell csv file and the corresponding list of channel names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mp.SpatialDataset(\n",
    "    input_path=\"crc_tutorial/singlecell.csv\",\n",
    "    channel_path=\"crc_tutorial/channel_names.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: patch images and mask cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will generate image patches (of specified size and resolution) using the spatial data set, followed by masking out cytotoxic T cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16  # Patch size in pixels\n",
    "pixel_size = 3  # Pixel size in microns\n",
    "cell_types = [\"Tcytotoxic\", \"Tumor\"]  # Specify the cell types of interest\n",
    "mask_cell_types = [\"Tcytotoxic\"]\n",
    "dataset.generate_masked_patch(\n",
    "    cell_to_mask=mask_cell_types,\n",
    "    cell_types=cell_types,\n",
    "    patch_size=patch_size,\n",
    "    pixel_size=pixel_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: generate data splits for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate train, validation, and test data splits for model training, where split is done at the patient level. We want to stratify our splits by the label we want to predict by specifying the `stratify_by` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = \"Contains_Tcytotoxic\"\n",
    "dataset.generate_data_splits(stratify_by=colname, specify_split=patient_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: train classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating data splits, we train a unet model to predict the presence of T cells from masked patches. A model instance is first created using the `PatchClassifier` class and trained by calling the `train` function. \n",
    "\n",
    "Feel free to skip this step and proceed directly to step 5 as a trained model has already been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_arch = \"unet\"\n",
    "n_channels = dataset.n_channels\n",
    "img_size = dataset.img_size\n",
    "\n",
    "model = mp.PatchClassifier(n_channels, img_size, model_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer_params = {\n",
    "    \"max_epochs\": 30,\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"logger\": False,\n",
    "}\n",
    "model = mp.train(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    predict_label=colname,\n",
    "    trainer_params=trainer_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: generate counterfactuals using trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in perturbations that can drive T cells to infiltrate tumor, we only need to generate counterfactuals (cf) for (training) patches containing tumor but no T cells. We pass theses specific patches to `get_counterfactual` under the parameter `images` along with the path to a trained classifier under the parameter `model_path`. Note that by default a pre-downloaded unet is passed as argument for reproduction purposes, you can change this to point to your own trained unet from the train step above.\n",
    "\n",
    "During cf generation, we will build a kdtree from the training patches. Then this kdtree is used to generate countefactual for each patch independently. Hence cf generation can (and needs to) be parallelized to achieve massive speed boos. Counterfactual generation per instance may be on the order of minutes. For large number of input instances, setting `num_workers` to be greater than 1 enables Ray parallelization and speeds things up. In order to complete cf generation on the order of hours (instead of days), we will need to distribute the instances across a large cluster, follow instructions [here]('https://doi.org/10.1016/j.cmet.2023.04.013') for using Ray with Slurm. A HPC version of this tutorial notebook that includes slurm job submission will be available soon, feel free to open a github issue if this would be helpful to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select tumor patches that do not contain T cells from training cohort to generate counterfactuals\n",
    "dataset.get_split_info()\n",
    "select_metadata = dataset.metadata[\n",
    "    (dataset.metadata[\"Contains_Tumor\"] == 1)\n",
    "    & (dataset.metadata[\"Contains_Tcytotoxic\"] == 0)\n",
    "    & (dataset.metadata[\"splits\"] == \"train\")\n",
    "]\n",
    "\n",
    "# example of selected instances to generate counterfactuals\n",
    "print(f\"Number of selected instances: {len(select_metadata)}\")\n",
    "print(select_metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for counterfactual generation\n",
    "optimization_param = {\n",
    "    \"use_kdtree\": True,\n",
    "    \"theta\": 50.0,\n",
    "    \"kappa\": -0.34,\n",
    "    \"learning_rate_init\": 0.1,\n",
    "    \"beta\": 80.0,\n",
    "    \"max_iterations\": 1000,\n",
    "    \"c_init\": 1000.0,\n",
    "    \"c_steps\": 5,\n",
    "    \"channel_to_perturb\": [\n",
    "        \"Glnsynthetase\",\n",
    "        \"CCR4\",\n",
    "        \"PDL1\",\n",
    "        \"LAG3\",\n",
    "        \"CD105endoglin\",\n",
    "        \"TIM3\",\n",
    "        \"CXCR4\",\n",
    "        \"PD1\",\n",
    "        \"CYR61\",\n",
    "        \"CD44\",\n",
    "        \"IL10\",\n",
    "        \"CXCL12\",\n",
    "        \"CXCR3\",\n",
    "        \"Galectin9\",\n",
    "        \"YAP\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Generate counterfactuals using trained model\n",
    "mp.get_counterfactual(\n",
    "    images=select_metadata,\n",
    "    dataset=dataset,\n",
    "    target_class=1,\n",
    "    model_path=model_path,  # for paper reproduction purpose, set to pre-downloaded model\n",
    "    optimization_params=optimization_param,\n",
    "    save_dir=f\"{dataset.root_dir}/cf/example/\",\n",
    "    device=\"cpu\",\n",
    "    num_workers=os.cpu_count(),  # set to greater than 1 for cpu parallelization with Ray\n",
    "    verbosity=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequently Asked Questions\n",
    "\n",
    "**Code in this section is not meant to be executed, they are for educational purposes only!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How do I use my own classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load your custom predictor class\n",
    "from crc_tutorial.model.my_model import (\n",
    "    MyOwnModel,\n",
    ")  # IMPORTANT: model must be available as a python module\n",
    "import torch\n",
    "\n",
    "# Step 2: Initialize the predictor\n",
    "predictor = MyOwnModel(img_size=img_size, in_channels=n_channels)\n",
    "\n",
    "# Step 3: Train the predictor\n",
    "predictor.train()\n",
    "\n",
    "# Step 4: Save the entire model\n",
    "torch.save(predictor, \"my_model.pth\")\n",
    "\n",
    "# Step 5: pass the model path to the get_counterfactual function\n",
    "mp.get_counterfactual(\n",
    "    ...,\n",
    "    model_path=\"my_model.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morpheus-spatial-QPyOikvw-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
